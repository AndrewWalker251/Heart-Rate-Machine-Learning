{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gpxpy\n",
    "import gpxpy.gpx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Load_gpx(filename):\n",
    "    gpx_file = open('{}.gpx'.format(filename), 'r') \n",
    "    gpx = gpxpy.parse(gpx_file)\n",
    "    return gpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gpx = Load_gpx('Lunch_Run')\n",
    "#gpx = Load_gpx('Afternoon_Ride')\n",
    "#gpx = Load_gpx('Evening_Ride')\n",
    "gpx = Load_gpx('Evening_Ride_heart_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = ET.parse('Evening_Ride_heart_rate.gpx')\n",
    "root = tree.getroot()\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root[1]\n",
    "string = ET.tostring(root[1])\n",
    "#string\n",
    "#print string.split(\"hr>\")[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "#r = re.compile('hr>(.*?)</ns')\n",
    "#m = r.search(string)\n",
    "#if m:\n",
    "#    print m\n",
    "    #lyrics = m.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heart_rate = re.findall('hr>(.*?)</ns' ,string)\n",
    "len(heart_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Extract_speed(gpx):\n",
    "    speed = []\n",
    "\n",
    "    for track in gpx.tracks:\n",
    "        for segment in track.segments:\n",
    "            for point_no, point in enumerate(segment.points):\n",
    "                if point.speed != None:\n",
    "                    print \"Speed=\", point.speed\n",
    "                elif point_no > 0:\n",
    "                    #print \"Calculated speed=\", point.speed_between(segment.points[point_no - 1])\n",
    "                    speed.append(point.speed_between(segment.points[point_no - 1]))\n",
    "    return speed\n",
    "    \n",
    "def Extract_elevation(gpx):    \n",
    "    elevation = []\n",
    "    for track in gpx.tracks:\n",
    "        for segment in track.segments:\n",
    "            \n",
    "            for point in segment.points:\n",
    "                #print(segment.points)\n",
    "                elevation.append(point.elevation)\n",
    "    #print segment.points\n",
    "    return elevation\n",
    "\n",
    "\n",
    "#def Extract_heart(gpx):\n",
    " #   heart = []\n",
    "  #  for track in gpx.tracks:\n",
    "   #     for segment in track.segments:\n",
    "    #        for point in segment.points:\n",
    "     #           for extension in point.extensions:\n",
    "      #              for TrackPointExtension in extension.'gpxtpx:TrackPointExtensions':\n",
    "       #                 #print extension.TrackPointExtensions\n",
    "        #                    print point.extensions\n",
    "         #               #heart.append(extension.hr)\n",
    "    \n",
    "   #return extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input data for the machine learning\n",
    "speed = Extract_speed(gpx)\n",
    "elevation = Extract_elevation(gpx)\n",
    "#heart = Extract_heart(gpx)\n",
    "len(elevation)\n",
    "len(speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take elevation and manipulate\n",
    "gradient = []\n",
    "for value in range(1,len(elevation)):\n",
    "    gradient.append(elevation[value]-elevation[value-1])\n",
    "\n",
    "#Test and Train\n",
    "speed_array = np.asarray(speed)\n",
    "gradient_array = np.asarray(gradient)\n",
    "heart_array = np.asarray(heart_rate)\n",
    "heart_array = heart_array[:-1]\n",
    "\n",
    "speed_array\n",
    "heart_array = heart_array.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(speed_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(gradient_array, 'ro')\n",
    "plt.show()\n",
    "plt.plot(speed_array, 'bo')\n",
    "plt.show()\n",
    "plt.plot(heart_array, 'go')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature engineering. Create more features based on the proceeding 5 minutes\n",
    "def moving_average(a, n) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "gradient_average_30 = moving_average(gradient_array, 30)\n",
    "gradient_average_120 = moving_average(gradient_array, 120)\n",
    "gradient_average_240 = moving_average(gradient_array, 240)\n",
    "\n",
    "speed_average_30 = moving_average(speed_array, 30)\n",
    "speed_average_120  = moving_average(speed_array, 120)\n",
    "speed_average_240 = moving_average(speed_array, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(gradient_average_30, 'ro')\n",
    "plt.show()\n",
    "plt.plot(gradient_average_120, 'bo')\n",
    "plt.show()\n",
    "plt.plot(gradient_average_240, 'go')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(speed_average_30, 'ro')\n",
    "plt.show()\n",
    "plt.plot(speed_average_120, 'bo')\n",
    "plt.show()\n",
    "plt.plot(speed_average_240, 'go')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "half = len(heart_array)/2\n",
    "heart_input_train = heart_array[:-half]\n",
    "speed = speed_array[:-half]\n",
    "speed_test = speed_array[-half:]\n",
    "gradient_test= gradient_array[-half:]\n",
    "actual_heart = heart_array[-half:]   \n",
    "gradient_train = gradient_array[:-half]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "Train_speed = speed.reshape(-1,1)\n",
    "Train_heart =heart_input_train.reshape(-1,1)\n",
    "Train_gradient = gradient_train.reshape(-1,1)\n",
    "Test_speed = speed_test.reshape(-1,1)\n",
    "Actual_heart = actual_heart.reshape(-1,1)\n",
    "Test_gradient = gradient_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(speed_array[-half:]  , heart_rate[-half:], 'bo')\n",
    "#plt.plot(gradient_array[-half:]  , heart_rate[-half:], 'ro')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(Train_speed, Train_heart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "heart_rate_predicted_regression = reg.predict(Test_speed)\n",
    "#heart_rate_predicted_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(Test_speed ,heart_rate_predicted_regression, 'bo')\n",
    "plt.plot(Test_speed ,Actual_heart, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "#print('Coefficients: \\n', reg.coef_)\n",
    "\n",
    "reg.coef_\n",
    "reg.intercept_\n",
    "# The mean squared error\n",
    "#print(\"Mean squared error: %.2f\"\n",
    "#      % mean_squared_error(grad2, prediction_grad))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "#print('Variance score: %.2f' % r2_score(grad2, prediction_grad))\n",
    "\n",
    "reg.score(Train_speed, Train_heart)\n",
    "\n",
    "# should i be getting it between 0 and 1. get rid of the variation. can't remember what it's  called. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now do it for the gradient instead of the speed\n",
    "# Create linear regression object\n",
    "reg_grad = linear_model.LinearRegression()\n",
    "reg_grad.fit(Train_gradient, Train_heart)\n",
    "heart_rate_predicted_on_gradient = reg_grad.predict(Test_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Test_gradient ,heart_rate_predicted_on_gradient, 'bo')\n",
    "plt.plot(Test_gradient ,Actual_heart, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_grad.score(Train_gradient, Train_heart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lets see if we can do a multiple linear regression that basically takes in both variables. \n",
    "# combine the speed and gradient data. \n",
    "combined_data= np.array([speed_array[0],gradient_array[0]])\n",
    "\n",
    "for i in range(1,len(speed_array)):\n",
    "    b= [speed_array[i], gradient_array[i]]\n",
    "    combined_data = np.vstack((combined_data ,b)) \n",
    "\n",
    "half = len(combined_data)/2\n",
    "    \n",
    "train_input_data = combined_data[:-half]\n",
    "test_input_data = combined_data[-half:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train_input_data)\n",
    "len(Train_heart)\n",
    "train_input_data.shape\n",
    "Train_heart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_two_linear = linear_model.LinearRegression()\n",
    "reg_two_linear.fit(train_input_data, Train_heart)\n",
    "heart_rate_predicted_on_both = reg_two_linear.predict(test_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Test_speed ,heart_rate_predicted_on_both, 'bo')\n",
    "plt.plot(Test_speed ,Actual_heart, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_two_linear.score(train_input_data, Train_heart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a very tiny improvement from using both. Now i've a number of options that include using the engineered features and also none linear fits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SVR time\n",
    "from sklearn.svm import SVR\n",
    "clf = SVR(kernel = 'poly', epsilon=0.2)\n",
    "#clf.fit(train_input_data, Train_heart) \n",
    "clf.fit(Train_speed, Train_heart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVR_pre = clf.predict(Test_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Test_speed ,SVR_pre, 'bo')\n",
    "plt.plot(Test_speed ,Actual_heart, 'ro')\n",
    "plt.show()\n",
    "clf.score(Train_speed, Train_heart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what we could do is create this neatly to run through some of the different options. \n",
    "# now to get the SVR to take in both speed and gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = SVR(kernel = 'poly', epsilon=0.2)\n",
    "#clf.fit(train_input_data, Train_heart) \n",
    "clf.fit(train_input_data, Train_heart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVR_pre = clf.predict(test_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Test_speed ,SVR_pre, 'bo')\n",
    "plt.plot(Test_speed ,Actual_heart, 'ro')\n",
    "plt.show()\n",
    "clf.score(train_input_data, Train_heart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# again small improvement . now i need to add in the engineered features. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
